# -*- coding: utf-8 -*-
import pandas as pd
from sklearn.preprocessing import StandardScaler

def normalize_datasets(train_csv, verify_csv, test_csv,
                       train_out_csv, verify_out_csv, test_out_csv,
                       feature_columns):
    """
    è¯»å–è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†çš„ CSV æ–‡ä»¶ï¼Œå¯¹æŒ‡å®šçš„ç‰¹å¾åˆ—è¿›è¡Œæ ‡å‡†åŒ–ï¼ˆZ-scoreæ ‡å‡†åŒ–ï¼‰ã€‚
    æ³¨æ„ï¼šå½’ä¸€åŒ–æ—¶å¿…é¡»ä½¿ç”¨è®­ç»ƒé›†çš„å‡å€¼å’Œæ ‡å‡†å·®å¯¹éªŒè¯é›†å’Œæµ‹è¯•é›†è¿›è¡Œè½¬æ¢ï¼Œ
          è¿™æ ·ç¡®ä¿è®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•æ•°æ®åœ¨ç›¸åŒçš„å°ºåº¦ä¸‹è¿›è¡Œæ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ã€‚

    å‚æ•°ï¼š
      train_csv: è®­ç»ƒé›†è¾“å…¥ CSV æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚ processed_train_fft.csvï¼‰
      verify_csv: éªŒè¯é›†è¾“å…¥ CSV æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚ processed_verify_fft.csvï¼‰
      test_csv: æµ‹è¯•é›†è¾“å…¥ CSV æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚ processed_test_fft.csvï¼‰
      train_out_csv: å½’ä¸€åŒ–åè®­ç»ƒé›†è¾“å‡º CSV æ–‡ä»¶è·¯å¾„
      verify_out_csv: å½’ä¸€åŒ–åéªŒè¯é›†è¾“å‡º CSV æ–‡ä»¶è·¯å¾„
      test_out_csv: å½’ä¸€åŒ–åæµ‹è¯•é›†è¾“å‡º CSV æ–‡ä»¶è·¯å¾„
      feature_columns: éœ€è¦å½’ä¸€åŒ–çš„ç‰¹å¾åˆ—åˆ—è¡¨

    è¾“å‡ºï¼š
      å°†å½’ä¸€åŒ–åçš„è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†åˆ†åˆ«ä¿å­˜åˆ°æŒ‡å®š CSV æ–‡ä»¶ä¸­ï¼ŒåŒæ—¶åœ¨ç»ˆç«¯è¾“å‡ºæç¤ºä¿¡æ¯ã€‚
    """
    print("ğŸš€ å¼€å§‹è¯»å–è®­ç»ƒé›†æ•°æ®...")
    try:
        df_train = pd.read_csv(train_csv)
        print(f"âœ… è®­ç»ƒé›†æ ·æœ¬æ•°ï¼š{df_train.shape[0]}")
    except Exception as e:
        print(f"âŒ è¯»å–è®­ç»ƒé›† CSV æ–‡ä»¶ {train_csv} å‡ºé”™ï¼š{e}")
        return

    print("ğŸš€ å¼€å§‹è¯»å–éªŒè¯é›†æ•°æ®...")
    try:
        df_verify = pd.read_csv(verify_csv)
        print(f"âœ… éªŒè¯é›†æ ·æœ¬æ•°ï¼š{df_verify.shape[0]}")
    except Exception as e:
        print(f"âŒ è¯»å–éªŒè¯é›† CSV æ–‡ä»¶ {verify_csv} å‡ºé”™ï¼š{e}")
        return

    print("ğŸš€ å¼€å§‹è¯»å–æµ‹è¯•é›†æ•°æ®...")
    try:
        df_test = pd.read_csv(test_csv)
        print(f"âœ… æµ‹è¯•é›†æ ·æœ¬æ•°ï¼š{df_test.shape[0]}")
    except Exception as e:
        print(f"âŒ è¯»å–æµ‹è¯•é›† CSV æ–‡ä»¶ {test_csv} å‡ºé”™ï¼š{e}")
        return

    # æ£€æŸ¥ç‰¹å¾åˆ—æ˜¯å¦å­˜åœ¨
    for df_name, df in [("è®­ç»ƒé›†", df_train), ("éªŒè¯é›†", df_verify), ("æµ‹è¯•é›†", df_test)]:
        missing = [col for col in feature_columns if col not in df.columns]
        if missing:
            print(f"âŒ {df_name} ç¼ºå°‘ä»¥ä¸‹ç‰¹å¾åˆ—ï¼š{missing}")
            return

    # åˆ›å»º StandardScaler å¹¶ç”¨è®­ç»ƒé›†æ‹Ÿåˆ
    scaler = StandardScaler()
    try:
        X_train = df_train[feature_columns].values
        scaler.fit(X_train)
        print("âœ… è®­ç»ƒé›†å½’ä¸€åŒ–å‚æ•°ï¼ˆå‡å€¼å’Œæ ‡å‡†å·®ï¼‰å·²è®¡ç®—")
    except Exception as e:
        print(f"âŒ è®­ç»ƒé›†å½’ä¸€åŒ–æ‹Ÿåˆå‡ºé”™ï¼š{e}")
        return

    # åˆ†åˆ«å¯¹è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†è¿›è¡Œè½¬æ¢
    try:
        X_train_norm = scaler.transform(X_train)
        X_verify_norm = scaler.transform(df_verify[feature_columns].values)
        X_test_norm = scaler.transform(df_test[feature_columns].values)
        print("âœ… è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†å‡å·²è¿›è¡Œæ ‡å‡†åŒ–è½¬æ¢")
    except Exception as e:
        print(f"âŒ æ•°æ®è½¬æ¢å‡ºé”™ï¼š{e}")
        return

    # æ„é€ å½’ä¸€åŒ–åçš„ DataFrame
    df_train_norm = pd.DataFrame(X_train_norm, columns=feature_columns)
    df_verify_norm = pd.DataFrame(X_verify_norm, columns=feature_columns)
    df_test_norm = pd.DataFrame(X_test_norm, columns=feature_columns)

    # å¦‚æœåŸæ•°æ®ä¸­æœ‰åŠ¨ä½œæ ‡ç­¾ actionTypeï¼Œåˆ™åŠ ä¸Š
    if "actionType" in df_train.columns:
        df_train_norm["actionType"] = df_train["actionType"]
    if "actionType" in df_verify.columns:
        df_verify_norm["actionType"] = df_verify["actionType"]
    if "actionType" in df_test.columns:
        df_test_norm["actionType"] = df_test["actionType"]

    # ä¿å­˜å½’ä¸€åŒ–åçš„æ•°æ®åˆ° CSV æ–‡ä»¶
    try:
        df_train_norm.to_csv(train_out_csv, index=False)
        print(f"âœ… å½’ä¸€åŒ–åçš„è®­ç»ƒé›†æ•°æ®å·²ä¿å­˜è‡³ï¼š{train_out_csv}")
    except Exception as e:
        print(f"âŒ ä¿å­˜è®­ç»ƒé›† CSV æ–‡ä»¶å‡ºé”™ï¼š{e}")

    try:
        df_verify_norm.to_csv(verify_out_csv, index=False)
        print(f"âœ… å½’ä¸€åŒ–åçš„éªŒè¯é›†æ•°æ®å·²ä¿å­˜è‡³ï¼š{verify_out_csv}")
    except Exception as e:
        print(f"âŒ ä¿å­˜éªŒè¯é›† CSV æ–‡ä»¶å‡ºé”™ï¼š{e}")

    try:
        df_test_norm.to_csv(test_out_csv, index=False)
        print(f"âœ… å½’ä¸€åŒ–åçš„æµ‹è¯•é›†æ•°æ®å·²ä¿å­˜è‡³ï¼š{test_out_csv}")
    except Exception as e:
        print(f"âŒ ä¿å­˜æµ‹è¯•é›† CSV æ–‡ä»¶å‡ºé”™ï¼š{e}")

if __name__ == "__main__":
    # è¾“å…¥è·¯å¾„
    TRAIN_INPUT_CSV = r"..\Result\Data\Test_FFT.csv"
    VERIFY_INPUT_CSV = r"..\Result\Data\Test_FFT.csv"
    TEST_INPUT_CSV  = r"..\Result\Data\Test_FFT.csv"
    # TRAIN_INPUT_CSV = "D:/vscode_work/badminton_classification/data/processed/processed_train_fft.csv"
    # VERIFY_INPUT_CSV = "D:/vscode_work/badminton_classification/data/processed/processed_verify_fft.csv"
    # TEST_INPUT_CSV  = "D:/vscode_work/badminton_classification/data/processed/processed_test_fft.csv"

    # è¾“å‡ºè·¯å¾„
    TRAIN_OUTPUT_CSV = r"..\Result\Data\Test_Normalize.csv"
    # TRAIN_OUTPUT_CSV = "D:/vscode_work/badminton_classification/data/processed/processed_train_fft_normalized.csv"
    # VERIFY_OUTPUT_CSV = "D:/vscode_work/badminton_classification/data/processed/processed_verify_fft_normalized.csv"
    # TEST_OUTPUT_CSV  = "D:/vscode_work/badminton_classification/data/processed/processed_test_fft_normalized.csv"

    # ç‰¹å¾åˆ—
    feature_columns = [
        "Ax_fft_mean", "Ax_fft_std", "Ax_fft_max", "Ax_dom_bin",
        "Ay_fft_mean", "Ay_fft_std", "Ay_fft_max", "Ay_dom_bin",
        "Az_fft_mean", "Az_fft_std", "Az_fft_max", "Az_dom_bin",
        "angularSpeedX_fft_mean", "angularSpeedX_fft_std", "angularSpeedX_fft_max", "angularSpeedX_dom_bin",
        "angularSpeedY_fft_mean", "angularSpeedY_fft_std", "angularSpeedY_fft_max", "angularSpeedY_dom_bin",
        "angularSpeedZ_fft_mean", "angularSpeedZ_fft_std", "angularSpeedZ_fft_max", "angularSpeedZ_dom_bin"
    ]

    print("ğŸš€ å¼€å§‹å¯¹è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–å½’ä¸€åŒ–...")
    normalize_datasets(TRAIN_INPUT_CSV, VERIFY_INPUT_CSV, TEST_INPUT_CSV,
                       TRAIN_OUTPUT_CSV, None, None,
                       feature_columns)
