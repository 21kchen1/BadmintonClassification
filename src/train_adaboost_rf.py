# -*- coding: utf-8 -*-
import os
import pandas as pd
import numpy as np
from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
import pickle

def load_data(csv_path):
    print(f"ğŸš€ æ­£åœ¨åŠ è½½æ•°æ®æ–‡ä»¶ï¼š{csv_path}")
    try:
        df = pd.read_csv(csv_path)
        print(f"âœ… æˆåŠŸè¯»å– CSV æ–‡ä»¶ï¼Œæ ·æœ¬æ•°é‡ï¼š{df.shape[0]}")
        return df
    except Exception as e:
        print(f"âŒ è¯»å– CSV æ–‡ä»¶ {csv_path} å‡ºé”™ï¼š{e}")
        return None

def prepare_data(df, feature_columns, label_column="actionType"):
    print("ğŸš€ æ­£åœ¨å‡†å¤‡æ•°æ®ï¼ˆåˆ†ç¦»ç‰¹å¾å’Œæ ‡ç­¾ï¼‰...")
    if label_column not in df.columns:
        print(f"âŒ æ ‡ç­¾åˆ— {label_column} ä¸å­˜åœ¨ï¼")
        return None, None
    try:
        X = df[feature_columns].values
        y = df[label_column].values
        print(f"âœ… ç‰¹å¾æ•°æ®ç»´åº¦ï¼š{X.shape}ï¼Œæ ‡ç­¾æ•°é‡ï¼š{len(y)}")
        return X, y
    except Exception as e:
        print(f"âŒ æ•°æ®åˆ†ç¦»å‡ºé”™ï¼š{e}")
        return None, None

def train_adaboost_rf(X_train, y_train):
    print("ğŸš€ å¼€å§‹è®­ç»ƒ AdaBoostï¼ˆéšæœºæ£®æ—ç‰ˆï¼‰æ¨¡å‹...")
    try:
        base_estimator = RandomForestClassifier(
            n_estimators=30,
            max_depth=5,
            random_state=42,
            n_jobs=-1
        )
        ada_rf = AdaBoostClassifier(
            estimator=base_estimator,
            n_estimators=200,
            learning_rate=0.6,
            random_state=42,
            algorithm='SAMME'
        )
        ada_rf.fit(X_train, y_train)
        print("âœ… AdaBoostï¼ˆéšæœºæ£®æ—ç‰ˆï¼‰æ¨¡å‹è®­ç»ƒå®Œæˆ")
        return ada_rf
    except Exception as e:
        print(f"âŒ AdaBoostï¼ˆéšæœºæ£®æ—ç‰ˆï¼‰æ¨¡å‹è®­ç»ƒå¤±è´¥ï¼š{e}")
        return None

def evaluate_model(model, X, y, dataset_name="æµ‹è¯•é›†"):
    print(f"ğŸš€ å¼€å§‹è¯„ä¼°æ¨¡å‹åœ¨ {dataset_name} ä¸Šçš„è¡¨ç°...")
    try:
        y_pred = model.predict(X)
        acc = accuracy_score(y, y_pred)
        report = classification_report(y, y_pred)
        print(f"âœ… {dataset_name} å‡†ç¡®ç‡ï¼š{acc:.4f}")
        print(f"âœ… {dataset_name} åˆ†ç±»æŠ¥å‘Šï¼š\n{report}")
    except Exception as e:
        print(f"âŒ æ¨¡å‹è¯„ä¼°å‡ºé”™ï¼š{e}")

def save_model(model, model_path):
    print(f"ğŸš€ æ­£åœ¨ä¿å­˜æ¨¡å‹åˆ°ï¼š{model_path}")
    try:
        with open(model_path, "wb") as f:
            pickle.dump(model, f)
        print("âœ… æ¨¡å‹ä¿å­˜æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹ä¿å­˜å¤±è´¥ï¼š{e}")

if __name__ == "__main__":
    TRAIN_DATA_CSV  = "D:/vscode_work/badminton_classification/data/processed/processed_train_fft_normalized.csv"
    VERIFY_DATA_CSV = "D:/vscode_work/badminton_classification/data/processed/processed_verify_fft_normalized.csv"
    TEST_DATA_CSV   = "D:/vscode_work/badminton_classification/data/processed/processed_test_fft_normalized.csv"
    MODEL_SAVE_PATH = "D:/vscode_work/badminton_classification/models/adaboost_rf_model.pkl"

    feature_columns = [
        "Ax_fft_mean", "Ax_fft_std", "Ax_fft_max", "Ax_dom_bin",
        "Ay_fft_mean", "Ay_fft_std", "Ay_fft_max", "Ay_dom_bin",
        "Az_fft_mean", "Az_fft_std", "Az_fft_max", "Az_dom_bin",
        "angularSpeedX_fft_mean", "angularSpeedX_fft_std", "angularSpeedX_fft_max", "angularSpeedX_dom_bin",
        "angularSpeedY_fft_mean", "angularSpeedY_fft_std", "angularSpeedY_fft_max", "angularSpeedY_dom_bin",
        "angularSpeedZ_fft_mean", "angularSpeedZ_fft_std", "angularSpeedZ_fft_max", "angularSpeedZ_dom_bin"
    ]

    print("ğŸš€ è¯»å–å¹¶å‡†å¤‡è®­ç»ƒé›†æ•°æ®...")
    df_train = load_data(TRAIN_DATA_CSV)
    X_train, y_train = prepare_data(df_train, feature_columns)

    print("ğŸš€ è¯»å–å¹¶å‡†å¤‡éªŒè¯é›†æ•°æ®...")
    df_verify = load_data(VERIFY_DATA_CSV)
    X_verify, y_verify = prepare_data(df_verify, feature_columns)

    print("ğŸš€ è¯»å–å¹¶å‡†å¤‡æµ‹è¯•é›†æ•°æ®...")
    df_test = load_data(TEST_DATA_CSV)
    X_test, y_test = prepare_data(df_test, feature_columns)

    model = train_adaboost_rf(X_train, y_train)

    evaluate_model(model, X_train, y_train, dataset_name="è®­ç»ƒé›†")
    evaluate_model(model, X_verify, y_verify, dataset_name="éªŒè¯é›†")
    evaluate_model(model, X_test, y_test, dataset_name="æµ‹è¯•é›†")

    save_model(model, MODEL_SAVE_PATH)
